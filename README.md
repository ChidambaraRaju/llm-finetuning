# LLM Engineering & Deployment - A 9-Week Learning Journey

This repository documents my progress, notes, code, and projects as I work through the **LLM Engineering & Deployment Certification Program** by Ready Tensor.

My goal is to document all the content I learn throughout this 9-week journey. This repo will serve as a log of my hands-on work, from fine-tuning models to deploying them in a production environment.

## About the Program

The Ready Tensor LLM Engineering & Deployment Certification is a hands-on program designed to bridge the gap between LLM development and real-world deployment.

The curriculum focuses on mastering the complete lifecycle of large language models. This includes:
* Adapting and fine-tuning open-source foundation models.
* Optimizing models for specific domains.
* Deploying models as reliable, scalable, and cost-effective systems in the cloud.

A key focus is building practical "cloud fluency" alongside model engineering skills, as this is a critical requirement for modern AI roles.

## My 9-Week Roadmap

The program is structured into two main modules over nine weeks, culminating in two portfolio-grade capstone projects.

### Module 1: LLM Fine-Tuning & Optimization
This module covers adapting open-source models using tools like Hugging Face, DeepSpeed, and Axolotl. It includes dataset preparation, parameter-efficient training, evaluation, and optimization.

### Module 2: LLM Deployment & Production Engineering
This module focuses on deploying, monitoring, and maintaining models on platforms like AWS SageMaker, Bedrock, and vLLM. It covers inference, scalability, cost-performance tradeoffs, and production best practices.

---

### Weekly Breakdown

Here is the detailed schedule I will be following:

* **Week 1: Introduction to LLM Engineering**
    * **Key Themes:** Model types, use cases, and fine-tuning motivations.

* **Week 2: Fine-Tuning Building Blocks**
    * **Key Themes:** Tokenization, dataset preparation, LoRA/QLORA training.

* **Week 3: Fine-Tuning in Practice**
    * **Key Themes:** Full training runs using Hugging Face, Axolotl, DeepSpeed.

* **Week 4: Evaluation & Optimization**
    * **Key Themes:** `lm-eval`, model merging, quantization, and versioning.

* **Week 5: Module 1 Capstone Project**
    * **Deliverable:** Deliver a fine-tuned, evaluated, quantized model.

* **Week 6: AWS Foundations**
    * **Key Themes:** SageMaker training, Bedrock customization, and cost control.

* **Week 7: Inference & Deployment**
    * **Key Themes:** Deploy models using vLLM, Modal, or AWS endpoints.

* **Week 8: LLM Ops & Reliability**
    * **Key Themes:** Monitoring, observability, security, and governance.

* **Week 9: Module 2 Capstone Project**
    * **Deliverable:** Deploy a production-ready endpoint with monitoring.

## üõ†Ô∏è Tools & Technologies

Throughout this program, I will be gaining hands-on experience with the same tools modern AI teams rely on:

* **Model Training & Management:** Hugging Face
* **Optimization & Workflows:** DeepSpeed, Axolotl
* **Quantization:** Bitsandbytes / GGUF
* **Inference & Deployment:** vLLM, Modal
* **Cloud Platforms:** AWS SageMaker & Bedrock
* **Monitoring & Observability:** LangSmith & CloudWatch
* **Safety & Evaluation:** Giskard

## üöÄ Final Capstone Projects

This learning journey will result in two major, portfolio-grade deliverables:

1.  **Capstone 1:** Fine-tune and optimize a model for a defined task.
2.  **Capstone 2:** Deploy that model as a live endpoint with monitoring and documentation.

## Acknowledgements

This learning journey and repository structure are based on the **LLM Engineering & Deployment Certification Program** created by **Ready Tensor**. All curriculum content, project ideas, and weekly breakdowns are part of their excellent program.

---

*This repository is a work-in-progress. I will be updating it regularly as I complete each week of the program. Follow along to see my progress!*